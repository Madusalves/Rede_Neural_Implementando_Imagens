{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI/9tIwfRmYNh0pqucNriH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madusalves/Rede_Neural_Implementando_Imagens/blob/main/Rede_Neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5N9mjcmDh9sM"
      },
      "outputs": [],
      "source": [
        "# Implementando uma deep learning com uso de imagens\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()  # Definindo a conversao de imagem pra tensor\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte do treino do dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Cria um buffer para pegar dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform ) # Carrega parte da validação\n",
        "valloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n"
      ],
      "metadata": {
        "id": "7G2LKXUMij8p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " MNIST é um grande banco de dados de dígitos manuscritos, comumente usado para treinar vários sistemas de processamento de imagens."
      ],
      "metadata": {
        "id": "Muxmt8oKmFwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader) # Cria um iterador para treinar o tensor\n",
        "imagens, etiquetas = next(dataiter) # Armazena duas variaveis para a imagem\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r') # Dropa a imagem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "rbOgsc-jmHo5",
        "outputId": "7ef2b394-ccb4-4ab0-ae49-be8498a25c5d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bf91cc30130>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) # verifica as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) # verifica as dimensões do tensor de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZIA1uXPnnk3",
        "outputId": "df68ab17-bc65-4141-be3d-8c30b2bfbe77"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):  # Classe modelo para criar o esqueleto\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neuronios que se liagam a 128\n",
        "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neuroniosque se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neuronios que se ligam a 10\n",
        "        # para a camadade saida nao é necessario definir nada pois so precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x)) # função de ativação da camada de entrada para a camada interna 1\n",
        "        x = F.relu(self.linear2(x)) # função de ativação da camada interna 1 para a cmada interna 2\n",
        "        x = self.liner3(x) # função de ativação da camada interna 2 para camada de saida, nesse caso f(x) = x\n",
        "        return F.log_softmax(x, dim=1) # dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "KaDkCZCBosyO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a politica de atualização dos pesos e das bias\n",
        "  inicio = time() # timer para sabermos quanto tempo levou\n",
        "\n",
        "  criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
        "  EPOCHS = 10 # numero de epocas que o algoritimo rodará\n",
        "  modelo.train() # ativando o modo de treinamento do modelo\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0 # inicializando a perda acumulada da epoch em questao\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "      imagens = imagens.view(imagens.shape[0], -1) # convertendo imagens para vetores de 28*28\n",
        "      otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior\n",
        "\n",
        "      output = modelo(imagens.to(device)) # colocando os dados do modelo\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questao\n",
        "\n",
        "      perda_instantanea.backward() # back propagation a partir da perda\n",
        "\n",
        "      otimizador.step() # atualizando os pesos e as bias\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
        "\n",
        "    else:\n",
        "      print('Epoch {} - Perda resultante: {}'.format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "  print(\"\\nTempo de treino (em minutos) = \", (time()-inicio)/60)"
      ],
      "metadata": {
        "id": "jERFiDQyt_Gy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo,valloader, device):\n",
        "  conta_corretas, conta_todas = 0, 0\n",
        "  for imagens, etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1, 784)\n",
        "      #desativa  autograd para acelerar a validaçao. grafos computacionais dinamicos tem um custo alto de processamento\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device)) # outpu do modelo em escala logaritma\n",
        "\n",
        "        ps = torch.exp(logps) # converte output para escala normal\n",
        "        probab = list(ps.cpu().numpy()[0])\n",
        "        etiqueta_pred = probab.index(max(probab)) # converte o tensor em um numero\n",
        "        etiqueta_certa = etiquetas.numpy()[i]\n",
        "        if(etiqueta_certa == etiqueta_pred):\n",
        "          conta_corretas += 1\n",
        "        conta_todas\n",
        "    print('Total de imagens testadas = ', conta_todas)\n",
        "    print('\\nPrecisão do modelo = {}%'.format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "QCKvjCTPw5ka"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modulo()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k_n9eerD7M2n",
        "outputId": "0996d191-1d90-452b-b823-6b38fac9de99"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" modelo = Module()\\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\nmodelo.to(device) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}